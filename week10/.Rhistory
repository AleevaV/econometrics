model_14_4 <- Arima(y, order = c(3, 0, 0))
AIC(model_14_4)
# Q15:При помощи команды auto.arima подберите модель, которая лучше всего описывает поведение индекса реальных денежных доходов населения (HHI_Q_DIRI) на участке c начала 2008 года (с 1 квартала 2008 года до 4 квартала 2014 года включительно). В ответ введите AIC этой модели.
y15 <- y[62:89]
model_15 <- auto.arima(y15)
AIC(model_15)
# Q16: Всё по тем же данным об индексе реальных денежных доходов населения HHI_Q_DIRI (Отберите только первые 89 наблюдений, то есть последнее наблюдение будет за 4ый квартал 2014 года!) оцените модель ARIMA(2,1,0). Постройте прогноз на 3 шага вперёд. В ответ введите верхнюю границу 95% доверительного интервала для прогноза на 1-ый квартал 2015 года.
model_16 <- arima(y, order = c(2, 1, 0))
forecast(model_16, h = 3)
AIC(model_15)
# Q16: Всё по тем же данным об индексе реальных денежных доходов населения HHI_Q_DIRI (Отберите только первые 89 наблюдений, то есть последнее наблюдение будет за 4ый квартал 2014 года!) оцените модель ARIMA(2,1,0). Постройте прогноз на 3 шага вперёд. В ответ введите верхнюю границу 95% доверительного интервала для прогноза на 1-ый квартал 2015 года.
model_16 <- arima(y, order = c(2, 1, 0))
forecast(model_16, h = 3)
# Q17:Есть такой способ проверки точности построенных моделей. Вы строите модель по данным, выкидывая несколько последних точек. Потом по построенной модели делаете прогноз на эти точки и смотрите, насколько он похож на то, что случилось в реальности. В качестве критерия используют, к примеру, такую величину, как MSE (Mean Squared Error).
# Давайте попробуем использовать MSE (можете как найти пакет, который считает MSE (попробуйте сделать это сами :), так и посчитать его руками) для выбора лучшей модели для описания индекса реальных денежных доходов населения HHI_Q_DIRI. Проверять будем так: оценим модель, выкинув последние 3 точки (по наблюдениям с 1 по 86 включительно), построим прогноз на 3 шага вперёд и сравним его с реальными данными (MSE, соответственно, будем рассчитывать по этим 3 точкам, не по всему ряду).
# Какая из моделей будет лучшей по этому критерию?
# PS: Если у Вас возникают ошибки вида "invalid argument type:...", попробуйте к используемым в расчётах MSE переменным применить as.numeric(). Это приведёт разнородные форматы прогноза и исходных данных к простому числовому формату, после чего пользоваться ими станет несколько удобнее.
y
# Q17:Есть такой способ проверки точности построенных моделей. Вы строите модель по данным, выкидывая несколько последних точек. Потом по построенной модели делаете прогноз на эти точки и смотрите, насколько он похож на то, что случилось в реальности. В качестве критерия используют, к примеру, такую величину, как MSE (Mean Squared Error).
# Давайте попробуем использовать MSE (можете как найти пакет, который считает MSE (попробуйте сделать это сами :), так и посчитать его руками) для выбора лучшей модели для описания индекса реальных денежных доходов населения HHI_Q_DIRI. Проверять будем так: оценим модель, выкинув последние 3 точки (по наблюдениям с 1 по 86 включительно), построим прогноз на 3 шага вперёд и сравним его с реальными данными (MSE, соответственно, будем рассчитывать по этим 3 точкам, не по всему ряду).
# Какая из моделей будет лучшей по этому критерию?
# PS: Если у Вас возникают ошибки вида "invalid argument type:...", попробуйте к используемым в расчётах MSE переменным применить as.numeric(). Это приведёт разнородные форматы прогноза и исходных данных к простому числовому формату, после чего пользоваться ими станет несколько удобнее.
y[1:86]
# Q17:Есть такой способ проверки точности построенных моделей. Вы строите модель по данным, выкидывая несколько последних точек. Потом по построенной модели делаете прогноз на эти точки и смотрите, насколько он похож на то, что случилось в реальности. В качестве критерия используют, к примеру, такую величину, как MSE (Mean Squared Error).
# Давайте попробуем использовать MSE (можете как найти пакет, который считает MSE (попробуйте сделать это сами :), так и посчитать его руками) для выбора лучшей модели для описания индекса реальных денежных доходов населения HHI_Q_DIRI. Проверять будем так: оценим модель, выкинув последние 3 точки (по наблюдениям с 1 по 86 включительно), построим прогноз на 3 шага вперёд и сравним его с реальными данными (MSE, соответственно, будем рассчитывать по этим 3 точкам, не по всему ряду).
# Какая из моделей будет лучшей по этому критерию?
# PS: Если у Вас возникают ошибки вида "invalid argument type:...", попробуйте к используемым в расчётах MSE переменным применить as.numeric(). Это приведёт разнородные форматы прогноза и исходных данных к простому числовому формату, после чего пользоваться ими станет несколько удобнее.
y17 <- y[1:86]
model_17_1 <- Arima(y, order = c(1, 1, 3))
model_17_2 <- Arima(y, order = c(1, 1, 2))
model_17_3 <- Arima(y, order = c(2, 1, 2))
model_17_4 <- Arima(y, order = c(0, 1, 0))
model_17_1 <- Arima(y, order = c(1, 1, 3))
model_17_1 <- Arima(y, order = c(1, 1, 3),include.mean = FALSE)
model_17_1 <- Arima(y, order = c(1, 1, 3),include.mean = TRUE)
model_17_1 <- Arima(y, order = c(1, 1, 3),include.drift =  = TRUE)
model_17_1 <- Arima(y, order = c(1, 1, 3),include.drift   = TRUE)
summary(model_17_1)
summary(model_17_2)
library(hydroGOF)
install.packages("hydroGOF")
library(hydroGOF)
mse(model_17_2)
mse(model_17_2,obs = y17)
y17
forecast(model_17_2,y17)
f_2 <- forecast(model_17_2,y17)
f_2
f_2[1]
f_2[2]
f_2[3]
f_2[4]
f_2[5]
f_2[4]
mse(sim = f_2[4],obs = y17)
mse(f_2[4],y17)
length(f_2[4])
length(y_17)
length(y17)
length(y17[1])
y17[1]
y17[2]
y17[
y17
y17
y17
y17[1:100]
y17[1:86]
mse(f_2[4],y17[1:86])
list(y17)
y17
y17[,1]
y17[,2]
mse(f_2[4],y17[,2])
f_2[4]
f_2$mean
f_2$mean[,0]
f_2$mean[,1]
f_2$mean[1]
f_2$mean[1:86]
mse(f_2$mean[1:86],y17)
# Q18: В экономических (и не только, разумеется) временных рядах часто встречается такое явление, как сезонность: повторяющееся из года в год в одно и то же время года поведение ряда (самое простое: в сельском хозяйстве происходит спад зимой, в количестве туристов на морских курортах - скачок летом и так далее). Во многих случаях это явление стоит учитывать для повышения качества прогноза. Давайте попробуем добавить в модель для индекса реальных денежных доходов населения HHI_Q_DIRI (Отберите только первые 89 наблюдений, то есть последнее наблюдение будет за 4ый квартал 2014 года!) сезонную составляющую! Оцените модель ARIMA(1,1,0)xSARIMA(0,0,1) (на практике в SARIMA-часть модели редко вставляют больше одного MA или AR лага, а сезонные разности берут, если в данных обнаруживается сезонный единичный корень).
# В ответ введите AIC
mod_18 <- Arima(y, order = c(1, 1, 0), seasonal = c(0, 0, 1))
AIC(mod_1)
AIC(mod_18)
# Q19:Часто бывает полезно добавить в модель какие-нибудь внешние переменные (чтобы повысить точность прогнозирования, убрать из оценок интересующих Вас коэффициентов влияние "лишних" переменных или наоборот - изучить влияние какой-то переменной или какого-то события на изучаемый показатель). Именно этим мы сейчас и займёмся! Отберите только первые 89 наблюдений, то есть последнее наблюдение будет за 4ый квартал 2014 года!
# Давайте создадим дамми-переменную, соответствующую кризису 2008-2009 годов. Сделаем это следующим образом: она равна нулю везде (сгенерируем последовательность из 89 нулей), кроме 2008 и 2009 года (целиком - то есть, заменяем 8 значений на 1. Да, конечно, это неправильные границы, но во избежание споров все будем делать именно так! А если интересно - можете определить границы, как считаете нужным и сделать то же самое). И эту переменную добавим в модель ARIMA(1,1,1) (простую ARIMA, без сезонной части) для индекса реальных денежных доходов населения HHI_Q_DIRI (опцией xreg = НашаДаммиПеременная).
dummy <- rep(0,89)
# Q19:Часто бывает полезно добавить в модель какие-нибудь внешние переменные (чтобы повысить точность прогнозирования, убрать из оценок интересующих Вас коэффициентов влияние "лишних" переменных или наоборот - изучить влияние какой-то переменной или какого-то события на изучаемый показатель). Именно этим мы сейчас и займёмся! Отберите только первые 89 наблюдений, то есть последнее наблюдение будет за 4ый квартал 2014 года!
# Давайте создадим дамми-переменную, соответствующую кризису 2008-2009 годов. Сделаем это следующим образом: она равна нулю везде (сгенерируем последовательность из 89 нулей), кроме 2008 и 2009 года (целиком - то есть, заменяем 8 значений на 1. Да, конечно, это неправильные границы, но во избежание споров все будем делать именно так! А если интересно - можете определить границы, как считаете нужным и сделать то же самое). И эту переменную добавим в модель ARIMA(1,1,1) (простую ARIMA, без сезонной части) для индекса реальных денежных доходов населения HHI_Q_DIRI (опцией xreg = НашаДаммиПеременная).
d <- rep(0,89)
y[60:80]
y[64:72]
y[62:69]
d[62:69] <- 1
d
mod_19 <- Arima(y, order = c(1, 1, 1),xreg = d)
summary(mod_19)
# Q20:
set.seed(70)
y1 <- arima.sim(n=100, list(ar=0.7))
plot(y1,type="l",axes=T, ylab = "variable Y")
rect(20,-1000,25,1000,col="#FFCCEE",border="#FFCCEE")
rect(70,-1000,80,1000,col="#FFCCEE",border="#FFCCEE")
par(new=TRUE)
plot(y1,type="l",ylab="")
plot(y1,type="l",ylab="")
plot(y1,type="l",ylab="")
# Q20:
set.seed(70)
y1 <- arima.sim(n=100, list(ar=0.7))
plot(y1,type="l",axes=T, ylab = "variable Y")
rect(20,-1000,25,1000,col="#FFCCEE",border="#FFCCEE")
rect(70,-1000,80,1000,col="#FFCCEE",border="#FFCCEE")
par(new=TRUE)
plot(y1,type="l",ylab="")
set.seed(30)
y1 <- arima.sim(n=100, list(ar=0.7))
plot(y1,type="l",axes=T, ylab = "variable Y")
rect(20,-1000,25,1000,col="#00CCEE",border="#FFCCEE")
rect(70,-1000,80,1000,col="#FFCCEE",border="#FFCCEE")
par(new=TRUE)
plot(y1,type="l",ylab="")
set.seed(30)
y1 <- arima.sim(n=100, list(ar=0.7))
plot(y1,type="l",axes=T, ylab = "variable Y")
rect(20,-1000,25,1000,col="#00CCEE",border="#FFCCEE")
rect(70,-1000,80,1000,col="#FFCCEE",border="#FFCCEE")
par(new=TRUE)
plot(y1,type="l",ylab="")
set.seed(10)
y1 <- arima.sim(n=100, list(ar=0.7))
plot(y1,type="l",axes=F, ylab = "variable Y")
rect(20,-1000,25,1000,col="#FFCCEE",border="#FFCCEE")
rect(70,-1000,80,1000,col="#FFCCEE",border="#FFCCEE")
par(new=TRUE)
plot(y1,type="l",ylab="")
set.seed(30)
y1 <- arima.sim(n=100, list(ar=0.7))
plot(y1,type="p",axes=F, ylab = "variable Y")
rect(20,-1000,25,1000,col="#FFCCEE",border="#FFCCEE")
rect(70,-1000,80,1000,col="#FFCCEE",border="#FFCCEE")
par(new=TRUE)
plot(y1,type="l",ylab="")
library(ggplot2)
library(caret)
install.packages("caret")
library(caret)
# Q16:Для ответа на вопросы 16 - 17 Вам понадобится R и набор данных diamonds из пакета ggplot2. Здесь содержатся данные о цене бриллиантов в зависимости от количества карат, качества огранки, размера и других переменных. Также, помимо ggplot2, необходимо подключить пакет caret.
# C помощью какой команды можно отобрать случайным образом номера наблюдений так, чтобы мы случайным образом отобрали 70% наблюдений в нашей выборке? Отбор производите по переменной price.
y <- diamonds
# Q16:Для ответа на вопросы 16 - 17 Вам понадобится R и набор данных diamonds из пакета ggplot2. Здесь содержатся данные о цене бриллиантов в зависимости от количества карат, качества огранки, размера и других переменных. Также, помимо ggplot2, необходимо подключить пакет caret.
# C помощью какой команды можно отобрать случайным образом номера наблюдений так, чтобы мы случайным образом отобрали 70% наблюдений в нашей выборке? Отбор производите по переменной price.
h <- diamonds
set.seed(12345)
train_ind <- createDataPartition(h$price, p=0.8, list=FALSE)
h_train <- h[train_ind,]
h_test <- h[-train_ind,]
# Команда `set.seed(12345)` необходима для того, чтобы случайное разбиение выборки на обучающую и тестовую давало на разных компьютерах одинаковый результат, она задаёт на всех компьютерах одинаковое стартовое значение (зерно) генератора случайных чисел.
# По обучающей части оцените модель в которой логарифм цены линейно объясняется переменными log(carat)log(carat), log(depth)log(depth), log(table)log(table) и clarityclarity. Спрогнозируйте значения цены (именно для цены, а не логарифма) по тестовой части выборки. В ответ укажите сумму квадратов остатков, деленную на миллиард, по тестовой части выборки с точностью до целых.
model1 <- lm(data=h_train, price~log(carat)+log(depth)+log(table)+clarity)
predict(model1, h_test)
pred_1 = predict(model1, h_test)
# Команда `set.seed(12345)` необходима для того, чтобы случайное разбиение выборки на обучающую и тестовую давало на разных компьютерах одинаковый результат, она задаёт на всех компьютерах одинаковое стартовое значение (зерно) генератора случайных чисел.
# По обучающей части оцените модель в которой логарифм цены линейно объясняется переменными log(carat)log(carat), log(depth)log(depth), log(table)log(table) и clarityclarity. Спрогнозируйте значения цены (именно для цены, а не логарифма) по тестовой части выборки. В ответ укажите сумму квадратов остатков, деленную на миллиард, по тестовой части выборки с точностью до целых.
model1 <- lm(data=h_train, log(price)~log(carat)+log(depth)+log(table)+clarity)
pred_1 = predict(model1, h_test)
sum((pred_1 - log(h_test$price))^2)
pred_1 = predict(model1, h_test)
sum((pred_1 - h_test$price)^2)
sum((pred_1 - h_test$price)^2)/1000000000
pred_1 = predict(model1, h_train$price)
h_train
pred_1 = predict(model1, h_train$price)
pred_1 = predict(model1, h_test$price)
sum((pred_1 - h_test$price)^2)/1000000000
pred_1 = predict(model1,h_test)
sum((pred_1 - h_test$price)^2)/1000000000
# Команда `set.seed(12345)` необходима для того, чтобы случайное разбиение выборки на обучающую и тестовую давало на разных компьютерах одинаковый результат, она задаёт на всех компьютерах одинаковое стартовое значение (зерно) генератора случайных чисел.
# По обучающей части оцените модель в которой логарифм цены линейно объясняется переменными log(carat)log(carat), log(depth)log(depth), log(table)log(table) и clarityclarity. Спрогнозируйте значения цены (именно для цены, а не логарифма) по тестовой части выборки. В ответ укажите сумму квадратов остатков, деленную на миллиард, по тестовой части выборки с точностью до целых.
model1 <- lm(data=h_train, log(price)~log(carat)+log(depth)+log(table)+clarity)
pred_1 = predict(model1,h_test)
sum((pred_1 - h_test$price)^2)/1000000000
library(AER)
d <- CollegeDistance
data("CollegeDistance")
d <- data("CollegeDistance")
d
data("CollegeDistance")
data(CollegeDistance)
d <- data(CollegeDistance)
d
"
data("CollegeDistance")
data("CollegeDistance")
d <- CollegeDistance
d
ivreg(data=d, wage~education|gender+ethnicity+unemp+distance)
ivreg(data=d, wage~education|gender+ethnicity+unemp+distance)
d <- CollegeDistance
ivreg(data=d, wage~education|gender+ethnicity+unemp+distance)
ivreg(data=d, wage~education+gender|ethnicity+unemp+distance)
ivreg(data=d, wage~education+gender+unemp|ethnicity+distance)
ivreg(data=d, wage~education+gender+unemp+ethnicity|distance)
ivreg(data=d, wage~education+gender+unemp|ethnicity+distance)
ivreg(data=d, wage~education|gender+ethnicity+unemp+distance)
library(ggplot2)
library(caret)
library(AER)
# Q16:Для ответа на вопросы 16 - 17 Вам понадобится R и набор данных diamonds из пакета ggplot2. Здесь содержатся данные о цене бриллиантов в зависимости от количества карат, качества огранки, размера и других переменных. Также, помимо ggplot2, необходимо подключить пакет caret.
# C помощью какой команды можно отобрать случайным образом номера наблюдений так, чтобы мы случайным образом отобрали 70% наблюдений в нашей выборке? Отбор производите по переменной price.
h <- diamonds
# Команда `set.seed(12345)` необходима для того, чтобы случайное разбиение выборки на обучающую и тестовую давало на разных компьютерах одинаковый результат, она задаёт на всех компьютерах одинаковое стартовое значение (зерно) генератора случайных чисел.
# По обучающей части оцените модель в которой логарифм цены линейно объясняется переменными log(carat)log(carat), log(depth)log(depth), log(table)log(table) и clarityclarity. Спрогнозируйте значения цены (именно для цены, а не логарифма) по тестовой части выборки. В ответ укажите сумму квадратов остатков, деленную на миллиард, по тестовой части выборки с точностью до целых.
model1 <- lm(data=h_train, log(price)~log(carat)+log(table)+clarity)
set.seed(12345)
train_ind <- createDataPartition(h$price, p=0.8, list=FALSE)
h_train <- h[train_ind,]
h_test <- h[-train_ind,]
# Команда `set.seed(12345)` необходима для того, чтобы случайное разбиение выборки на обучающую и тестовую давало на разных компьютерах одинаковый результат, она задаёт на всех компьютерах одинаковое стартовое значение (зерно) генератора случайных чисел.
# По обучающей части оцените модель в которой логарифм цены линейно объясняется переменными log(carat)log(carat), log(depth)log(depth), log(table)log(table) и clarityclarity. Спрогнозируйте значения цены (именно для цены, а не логарифма) по тестовой части выборки. В ответ укажите сумму квадратов остатков, деленную на миллиард, по тестовой части выборки с точностью до целых.
model1 <- lm(data=h_train, log(price)~log(carat)+log(table)+clarity)
pred_1 = predict(model1,h_test)
sum((pred_1 - h_test$price)^2)/1000000000
# Команда `set.seed(12345)` необходима для того, чтобы случайное разбиение выборки на обучающую и тестовую давало на разных компьютерах одинаковый результат, она задаёт на всех компьютерах одинаковое стартовое значение (зерно) генератора случайных чисел.
# По обучающей части оцените модель в которой логарифм цены линейно объясняется переменными log(carat)log(carat), log(depth)log(depth), log(table)log(table) и clarityclarity. Спрогнозируйте значения цены (именно для цены, а не логарифма) по тестовой части выборки. В ответ укажите сумму квадратов остатков, деленную на миллиард, по тестовой части выборки с точностью до целых.
model1 <- lm(data=h_train, log(price)~log(carat)+log(table)+clarity)
pred_1 = predict(model1,h_test)
sum((pred_1 - h_test$price)^2)/1000000000
library(hydroGOF)
mse(pred_1,h_test$price)
mse(pred_1,h_test$price)/1000000000
# Команда `set.seed(12345)` необходима для того, чтобы случайное разбиение выборки на обучающую и тестовую давало на разных компьютерах одинаковый результат, она задаёт на всех компьютерах одинаковое стартовое значение (зерно) генератора случайных чисел.
# По обучающей части оцените модель в которой логарифм цены линейно объясняется переменными log(carat)log(carat), log(depth)log(depth), log(table)log(table) и clarityclarity. Спрогнозируйте значения цены (именно для цены, а не логарифма) по тестовой части выборки. В ответ укажите сумму квадратов остатков, деленную на миллиард, по тестовой части выборки с точностью до целых.
model1 <- lm(data=h_train, price~log(carat)+log(table)+clarity)
pred_1 = predict(model1,h_test)
sum((pred_1 - h_test$price)^2)/1000000000
library(hydroGOF)
mse(pred_1,h_test$price)/1000000000
# Q16:Для ответа на вопросы 16 - 17 Вам понадобится R и набор данных diamonds из пакета ggplot2. Здесь содержатся данные о цене бриллиантов в зависимости от количества карат, качества огранки, размера и других переменных. Также, помимо ggplot2, необходимо подключить пакет caret.
# C помощью какой команды можно отобрать случайным образом номера наблюдений так, чтобы мы случайным образом отобрали 70% наблюдений в нашей выборке? Отбор производите по переменной price.
h <- diamonds
train_ind <- createDataPartition(h$price, p=0.8, list=FALSE)
h_train <- h[train_ind,]
h_test <- h[-train_ind,]
# Команда `set.seed(12345)` необходима для того, чтобы случайное разбиение выборки на обучающую и тестовую давало на разных компьютерах одинаковый результат, она задаёт на всех компьютерах одинаковое стартовое значение (зерно) генератора случайных чисел.
# По обучающей части оцените модель в которой логарифм цены линейно объясняется переменными log(carat)log(carat), log(depth)log(depth), log(table)log(table) и clarityclarity. Спрогнозируйте значения цены (именно для цены, а не логарифма) по тестовой части выборки. В ответ укажите сумму квадратов остатков, деленную на миллиард, по тестовой части выборки с точностью до целых.
model1 <- lm(data=h_train, price~log(carat)+log(table)+clarity)
pred_1 = predict(model1,h_test)
sum((pred_1 - h_test$price)^2)/1000000000
h_test
h_test-h_test$price
# Команда `set.seed(12345)` необходима для того, чтобы случайное разбиение выборки на обучающую и тестовую давало на разных компьютерах одинаковый результат, она задаёт на всех компьютерах одинаковое стартовое значение (зерно) генератора случайных чисел.
# По обучающей части оцените модель в которой логарифм цены линейно объясняется переменными log(carat)log(carat), log(depth)log(depth), log(table)log(table) и clarityclarity. Спрогнозируйте значения цены (именно для цены, а не логарифма) по тестовой части выборки. В ответ укажите сумму квадратов остатков, деленную на миллиард, по тестовой части выборки с точностью до целых.
model1 <- lm(data=h_train, logprice~logcarat+logtable+clarity)
# Команда `set.seed(12345)` необходима для того, чтобы случайное разбиение выборки на обучающую и тестовую давало на разных компьютерах одинаковый результат, она задаёт на всех компьютерах одинаковое стартовое значение (зерно) генератора случайных чисел.
# По обучающей части оцените модель в которой логарифм цены линейно объясняется переменными log(carat)log(carat), log(depth)log(depth), log(table)log(table) и clarityclarity. Спрогнозируйте значения цены (именно для цены, а не логарифма) по тестовой части выборки. В ответ укажите сумму квадратов остатков, деленную на миллиард, по тестовой части выборки с точностью до целых.
model1 <- lm(data=h_train, log(price)~log(carat)+log(table)+clarity)
pred_1 = predict(model1,h_test)
sum((pred_1 - h_test$price)^2)/1000000000
library(hydroGOF)
mse(pred_1,h_test$price)/1000000000
mse(pred_1,h_test$price)/2000000000
sum((pred_1 - h_test$price)^2)/2000000000
sum((pred_1 - h_test$price)^2)/200000000
sum((pred_1 - h_test$price)^2)/2000000000
sum((pred_1 - h_test$price)^2)/20000000000
data("CollegeDistance")
d <- CollegeDistance
ivreg(data=d, wage~education|gender+ethnicity+unemp+distance)
ivreg(data=d, wage~education|distance)
ivreg(data=d, wage~education+gender+ethnicity+unemp|gender+ethnicity+unemp+distance)
train_ind <- createDataPartition(h, p=0.8, list=FALSE)
train_ind <- createDataPartition(h$price, p=0.8, list=FALSE)
h_train <- h[train_ind,]
h_test <- h[-train_ind,]
# Команда `set.seed(12345)` необходима для того, чтобы случайное разбиение выборки на обучающую и тестовую давало на разных компьютерах одинаковый результат, она задаёт на всех компьютерах одинаковое стартовое значение (зерно) генератора случайных чисел.
# По обучающей части оцените модель в которой логарифм цены линейно объясняется переменными log(carat)log(carat), log(depth)log(depth), log(table)log(table) и clarityclarity. Спрогнозируйте значения цены (именно для цены, а не логарифма) по тестовой части выборки. В ответ укажите сумму квадратов остатков, деленную на миллиард, по тестовой части выборки с точностью до целых.
model1 <- lm(data=h_train, log(price)~log(carat)+log(table)+clarity)
pred_1 = predict(model1,h_test)
sum((pred_1 - h_test$price)^2)/20000000000
data("CollegeDistance")
d <- CollegeDistance
ivreg(data=d, wage~education+gender+ethnicity+unemp|gender+ethnicity+unemp+distance)
ivreg(data=d, wage~education+gender+ethnicity+unemp+distance|gender+ethnicity+unemp+distance)
ivreg(data=d, wage~education+gender+ethnicity+unemp|gender+ethnicity+unemp+distance)
library(caret)
library(AER)
library(ggplot2)
library(caret)
library(erer)
library(lmtest)
library(sandwich)
library(forecast)
# Q15: Оцените модель зависимости расхода топлива (mpg) от мощности двигателя в лошадиных силах (hp), веса автомобиля (wt) и типа коробки передач (am). Проведите тест Бройша-Пагана, считая, что разброс остатков зависит от мощности, её квадрата, веса и его квадрата (всего 4 переменные). В ответ введите p-value этого теста с точностью до 3 знаков после запятой.
cars <- mtcars
model_15 <- lm(data=cars, mpg~hp+wt+am)
bptest(model_15, varformula = ~ 1 +hp+I(hp^2),wt+I(wt^2),data = cars)
bptest(model_15, varformula = ~ 1 +hp+I(hp^2)+wt+I(wt^2),data = cars)
# Q16:
gqtest(model_15, order.by = ~hp, data = cars, fraction = 0.2)
# Q16:
gqtest(model_15, order.by = ~hp, data = cars, fraction = 0.3)
# Q17:Для той же модели будем строить оценки ковариационной матрицы, устойчивые к гетероскедастичности. При каком типе оценок ковариация между весом и мощностью будет минимальной (просто минимальной, не по модулю!)
vcovHC(model_15,type="HC3")
# Q17:Для той же модели будем строить оценки ковариационной матрицы, устойчивые к гетероскедастичности. При каком типе оценок ковариация между весом и мощностью будет минимальной (просто минимальной, не по модулю!)
vcovHC(model_15,type="HC0")
vcovHC(model_15,type="HC1")
vcovHC(model_15,type="HC2")
vcovHC(model_15,type="HC3")
# Q21:Оцените пробит-модель для вероятности выжить на Титанике, взяв в качестве объясняющих переменных возраст, age, квадрат возраста, age^2
# пол, sex, класс, которым ехал пассажир, pclass, количество братьев/сестер/мужей/жен, sibsp.
# Найдите оценку дисперсии коэффициента при дамми-переменной, отвечающей за второй класс. Ответ введите так, как отражает R.
model_21 <- glm(data = t3, survived ~ sex + age +I(age^2)+ sibsp + pclass, family=binomial(link="logit") , x = TRUE)
setwd("C:/Users/Vera.Aleeva/Projects/Econometrics/week10")
# Q21:Оцените пробит-модель для вероятности выжить на Титанике, взяв в качестве объясняющих переменных возраст, age, квадрат возраста, age^2
# пол, sex, класс, которым ехал пассажир, pclass, количество братьев/сестер/мужей/жен, sibsp.
# Найдите оценку дисперсии коэффициента при дамми-переменной, отвечающей за второй класс. Ответ введите так, как отражает R.
t <- import("titanic3.csv")
library(dplyr)
library(broom)
library(vcd)
# Q21:Оцените пробит-модель для вероятности выжить на Титанике, взяв в качестве объясняющих переменных возраст, age, квадрат возраста, age^2
# пол, sex, класс, которым ехал пассажир, pclass, количество братьев/сестер/мужей/жен, sibsp.
# Найдите оценку дисперсии коэффициента при дамми-переменной, отвечающей за второй класс. Ответ введите так, как отражает R.
t <- import("titanic3.csv")
# Q21:Оцените пробит-модель для вероятности выжить на Титанике, взяв в качестве объясняющих переменных возраст, age, квадрат возраста, age^2
# пол, sex, класс, которым ехал пассажир, pclass, количество братьев/сестер/мужей/жен, sibsp.
# Найдите оценку дисперсии коэффициента при дамми-переменной, отвечающей за второй класс. Ответ введите так, как отражает R.
t <- read.csv("titanic3.csv")
model_21 <- glm(data = t, survived ~ sex + age +I(age^2)+ sibsp + pclass, family=binomial(link="logit") , x = TRUE)
summary(model_21)
vcov(model_21)
model_21 <- glm(data = t, survived ~ sex + age +I(age^2)+ sibsp + pclass, family=binomial(link="logit") E)
model_21 <- glm(data = t, survived ~ sex + age +I(age^2)+ sibsp + pclass, family=binomial(link="logit") E)
, x = TRU
model_21 <- glm(data = t, survived ~ sex + age +I(age^2)+ sibsp + pclass, family=binomial(link="logit") , x = TRUE)
summary(model_21)
vcov(model_21)
# Q21:Оцените пробит-модель для вероятности выжить на Титанике, взяв в качестве объясняющих переменных возраст, age, квадрат возраста, age^2
# пол, sex, класс, которым ехал пассажир, pclass, количество братьев/сестер/мужей/жен, sibsp.
# Найдите оценку дисперсии коэффициента при дамми-переменной, отвечающей за второй класс. Ответ введите так, как отражает R.
t <- read.csv("titanic3.csv")
model_21 <- glm(data = t, survived ~ sex + age +I(age^2)+ sibsp + pclass, family=binomial(link="logit") , x = TRUE)
summary(model_21)
vcov(model_21)
model_21 <- glm(data = t, survived ~ sex + age +I(age^2)+ sibsp + pclass, family=binomial(link='probit') , x = TRUE)
summary(model_21)
vcov(model_21)
# Q22: Найдите предельный эффект увеличения возраста на вероятность выжить для среднестатистического индивида. Ответ укажите с тремя знаками после запятой.
maBina(model_21)
# Q25: Оцените обычную линейную модель зависимости yy от x1x1 и x2x2. Используя робастную (устойчивую) к гетероскедастичности и автокорреляции ковариационную матрицу (с настройками по умолчанию), коэффициенты при каких переменных будут значимы на 10% уровне значимости?
model_25 <- lm(y~xq+x2)
# Q25: Оцените обычную линейную модель зависимости yy от x1x1 и x2x2. Используя робастную (устойчивую) к гетероскедастичности и автокорреляции ковариационную матрицу (с настройками по умолчанию), коэффициенты при каких переменных будут значимы на 10% уровне значимости?
model_25 <- lm(y~x1+x2)
set.seed(12)
y<-arima.sim(model = list (ar = c(0.1, 0.6), ma = -0.3), n=100)
x1<-rnorm(100, 15, 5)
x2<-runif(100, 45, 50)
# Q25: Оцените обычную линейную модель зависимости yy от x1x1 и x2x2. Используя робастную (устойчивую) к гетероскедастичности и автокорреляции ковариационную матрицу (с настройками по умолчанию), коэффициенты при каких переменных будут значимы на 10% уровне значимости?
model_25 <- lm(y~x1+x2)
coeftest(model_25,vcov. = vcovHC(model_25))
# Q25: Оцените обычную линейную модель зависимости y от x1 и x2.
# Используя робастную (устойчивую) к гетероскедастичности и автокорреляции ковариационную матрицу (с настройками по умолчанию),
# коэффициенты при каких переменных будут значимы на 10% уровне значимости?
model_25 <- lm(y~x1+x2)
coeftest(model_25,vcov. = vcovHC(model_25))
vcovHC(model_25)
coeftest(vcovHC(model_25))
coeftest(model_25,vcov. = vcovHC(model_25))
# Q26:Для той же модели проведите тест Бройша-Годфри с максимальным порядком корреляции, равным 3. Чему равно значение тестовой статистики? Введите ответ с точностью до 2 знаков после запятой
bgtest(model_25,order=3)
res <- summary(model_25)
res$residuals
coeftest(model_25,vcov. = vcovHC(model_25))
eps = res$residuals
eps[1:]
eps[1:-1]
eps[1]
eps
eps[1:100]
eps[2:100]
eps_1 = eps[2:100]
plot(eps,eps_1)
plot(eps[1:99],eps_1)
set.seed(123)
y<-arima.sim(model = list(ar = c(0.5, 0.1), ma = c(0.3,0.2)), n = 100)
# Q31: Какая из этих моделей будет лучшей по критерию AIC (для этих данных)?
model31_1 <- Arima(y, order = c(1, 1, 2))
# Q31: Какая из этих моделей будет лучшей по критерию AIC (для этих данных)?
model31_1 <- Arima(y, order = c(1, 1, 2))
model31_2 <- Arima(y, order = c(1, 1, 1))
model31_3 <- Arima(y, order = c(1, 1, 0))
model31_4 <- Arima(y, order = c(0, 1, 2))
AIC(model31_1)
AIC(model31_2)
AIC(model31_3)
AIC(model31_4)
# Q32:Вопрос вдохновлен вопросом с форума
# В жизни иногда бывает, что Вам нужно построить модель с несколькими лагами, идущими не по порядку начиная с первого (по умолчанию, Arima, если сказать ей построить AR(5), оценить все AR лаги с 1-ого до 5-ого, а Вам могут быть нужны только 3-ий и 5-ый), либо значения части коэффициентов Вам могут быть откуда-то известны (из предыдущего опыта, других исследований, так устроена изучаемая система и т.д.). Один из способов это сделать - использовать опцию fixed в команде Arima. Она позволяет зафиксировать значения части коэффициентов.
# Работает она очень просто: при использовании команды ARIMA нужно в fixed передать вектор известных Вам значений коэффициентов. Устроен он так: сперва все AR-лаги с первого до последнего, потом все MA-лаги с первого до последнего, потом константа. Там, где значения Вам известны (равны нулю, если хотите их просто выкинуть) ставьте эти известные значения (нули); там, где коэффициент Вы хотите оценить - ставьте NA. К примеру, для ARMA(2,2), где первый лаг AR Вам не нужен, получаем order = c(2,0,2), а fixed = c(0, NA, NA, NA, NA), где первый ноль - это первый AR лаг, который мы выкидываем; потом 1 NA для второго AR лага (который мы оцениваем); 2 NA для двух оцениваемых MA лагов; и последняя NA для константы, которая нам тоже нужна (если не нужна, можно поставить 0 вместо последнего NA).
# По сгенерированному в предыдущем вопросе ряду y оцените модель ARIMA(3,0,3) без первых лагов в AR и MA (то есть, нужно оценить вторые и третьи лаги в AR и MA и константу (про неё не забывайте, её тоже надо оценить!)). В ответ введите AIC этой модели с точностью до 2 знака после запятой.
model32 <- Arima(y, order = c(3, 0, 3),fixed = c(0, NA, NA, 0,NA, NA,0))
AIC(model32)
# Q32:Вопрос вдохновлен вопросом с форума
# В жизни иногда бывает, что Вам нужно построить модель с несколькими лагами, идущими не по порядку начиная с первого (по умолчанию, Arima, если сказать ей построить AR(5), оценить все AR лаги с 1-ого до 5-ого, а Вам могут быть нужны только 3-ий и 5-ый), либо значения части коэффициентов Вам могут быть откуда-то известны (из предыдущего опыта, других исследований, так устроена изучаемая система и т.д.). Один из способов это сделать - использовать опцию fixed в команде Arima. Она позволяет зафиксировать значения части коэффициентов.
# Работает она очень просто: при использовании команды ARIMA нужно в fixed передать вектор известных Вам значений коэффициентов. Устроен он так: сперва все AR-лаги с первого до последнего, потом все MA-лаги с первого до последнего, потом константа. Там, где значения Вам известны (равны нулю, если хотите их просто выкинуть) ставьте эти известные значения (нули); там, где коэффициент Вы хотите оценить - ставьте NA. К примеру, для ARMA(2,2), где первый лаг AR Вам не нужен, получаем order = c(2,0,2), а fixed = c(0, NA, NA, NA, NA), где первый ноль - это первый AR лаг, который мы выкидываем; потом 1 NA для второго AR лага (который мы оцениваем); 2 NA для двух оцениваемых MA лагов; и последняя NA для константы, которая нам тоже нужна (если не нужна, можно поставить 0 вместо последнего NA).
# По сгенерированному в предыдущем вопросе ряду y оцените модель ARIMA(3,0,3) без первых лагов в AR и MA (то есть, нужно оценить вторые и третьи лаги в AR и MA и константу (про неё не забывайте, её тоже надо оценить!)). В ответ введите AIC этой модели с точностью до 2 знака после запятой.
model32 <- Arima(y, order = c(3, 0, 3),fixed = c(0, NA, NA, 0,NA, NA,NA))
AIC(model32)
# Для выполнения вопросов 35-37 Вам потребуется R и пакеты caret, AER. Подгрузите массив данных CollegeDistance.
# Q35: Разделите весь набор данных на обучающую (90%) и тестовую (10%) части по переменной wagewage, предварительно задав set.seed(42).
# По обучающей части c помощью обычного МНК оцените модель зависимости заработной платы, wagewage, от пола, gendergender, этнической группы, ethnicityethnicity, безработицы в регионе, unempunemp, числа лет обучения, educationeducation и региона, regionregion.
# Чему равен коэффициент при длительности обучения? Значим ли он? Есть ли подозрения на эндогенность?
data('CollegeDistance.')
# Для выполнения вопросов 35-37 Вам потребуется R и пакеты caret, AER. Подгрузите массив данных CollegeDistance.
# Q35: Разделите весь набор данных на обучающую (90%) и тестовую (10%) части по переменной wagewage, предварительно задав set.seed(42).
# По обучающей части c помощью обычного МНК оцените модель зависимости заработной платы, wagewage, от пола, gendergender, этнической группы, ethnicityethnicity, безработицы в регионе, unempunemp, числа лет обучения, educationeducation и региона, regionregion.
# Чему равен коэффициент при длительности обучения? Значим ли он? Есть ли подозрения на эндогенность?
data('CollegeDistance')
d <- CollegeDistance
train_ind <- createDataPartition(d$wage, p=0.9, list=FALSE)
d_train <- d[train_ind,]
d_test <- d[-train_ind,]
model_35 <- lm(data=d_train,wage~gender+ethnicity+unemp+education+region)
summary(model_35)
d <- CollegeDistance
set.seed(42)
train_ind <- createDataPartition(d$wage, p=0.9, list=FALSE)
d_train <- d[train_ind,]
d_test <- d[-train_ind,]
model_35 <- lm(data=d_train,wage~gender+ethnicity+unemp+education+region)
summary(model_35)
d <- CollegeDistance
set.seed(42)
train_ind <- createDataPartition(d$wage, p=0.9, list=FALSE)
d_train <- d[train_ind,]
d_test <- d[-train_ind,]
model_35 <- lm(data=d_train,wage~gender+ethnicity+unemp+education+region)
summary(model_35)
RNGkind((sample.kind='Rounding'))
RNGkind((sample.kind = "Rounding"))
RNGkind((sample.kind="Rounding"))
RNGkind((sample.kind=rounding))
RNGkind((sample.kind="RNG"))
RNGkind(sample.kind = "Rounding")
set.seed(42)
train_ind <- createDataPartition(d$wage, p=0.9, list=FALSE)
d_train <- d[train_ind,]
d_test <- d[-train_ind,]
model_35 <- lm(data=d_train,wage~gender+ethnicity+unemp+education+region)
summary(model_35)
# Q36:
ivreg(data=d, wage~education+gender+ethnicity+unemp|gender+ethnicity+unemp+distance)
# Q36:
ivreg(data=d, wage~education+gender+ethnicity+unemp+region|region+gender+ethnicity+unemp+distance)
# Q36:
ivreg(data=d, wage~gender+ethnicity+unemp+education+region|gender+ethnicity+unemp+distance)
# Q36:
ivreg(data=d, wage~gender+ethnicity+unemp+education+region|region+gender+ethnicity+unemp+distance)
# Q36:
ivreg(data=d_train, wage~gender+ethnicity+unemp+education+region|region+gender+ethnicity+unemp+distance)
# Q36:
model_36 <- ivreg(data=d_train, wage~gender+ethnicity+unemp+education+region|region+gender+ethnicity+unemp+distance)
# Q37: Берём модель из предыдущего пункта.
# По обучающей части с помощью двухшагового МНК оцените модель зависимости заработной платы, wage, от пола, gender, этнической группы, ethnicity, безработицы в регионе, unemp,
# числа лет обучения, education и региона, region, используя в качестве инструментов все переменные, некоррелированные со способностями (region, gender, ethnicity, unemp, distance).
# Спрогнозируйте значения заработной платы по тестовой части выборки (10%). В ответ введите прогноз для первого значения. Ответ округляйте до трех знаков после запятой.
predict(model_36, d_test)
# Q37: Берём модель из предыдущего пункта.
# По обучающей части с помощью двухшагового МНК оцените модель зависимости заработной платы, wage, от пола, gender, этнической группы, ethnicity, безработицы в регионе, unemp,
# числа лет обучения, education и региона, region, используя в качестве инструментов все переменные, некоррелированные со способностями (region, gender, ethnicity, unemp, distance).
# Спрогнозируйте значения заработной платы по тестовой части выборки (10%). В ответ введите прогноз для первого значения. Ответ округляйте до трех знаков после запятой.
prognoz <- predict(model_36, d_test)
prognoz[1]
# Q13:Чему равна максимальная цена бриллиантов? Выберите наиболее близкое значение.
data <- diamonds
summary(data)
# Q14:Какое количество бриллиантов обладает премиум огранкой?
summary(data$cut)
library("ggplot2")
# Q11:Используя команду R pt(..., df=...), посчитайте вероятность P(Z < 4)P(Z<4),
# если Z имеет tt-распределение с 2 степенями свободы. Округляйте до двух знаков после запятой.
Z <- dt(df = 3)
# Q13:Чему равна максимальная цена бриллиантов? Выберите наиболее близкое значение.
data <- diamonds
summary(data)
# Q14:Какое количество бриллиантов обладает премиум огранкой?
summary(data$cut)
# Q16:Чему равна se(β1) в оценённой модели price=β1+β2carat?
# Округляйте до двух знаков после запятой.
model <- lm(data=data, price ~ carat)
summary(model)
#Q17:В модели pricei=β1+β2carat+ε на уровне значимости 5% проверьте гипотезу о том,
# что количество карат не оказывает влияния на стоимость бриллиантов.
summary(model)
# Q18:В модели pricei=β1+β2carati+β3xi+β4yi+εi
# при проверке гипотезы о влиянии ширины камня на стоимость бриллиантов на уровне значимости 1% чему равно P-значение?
model1 <- lm(data=data, price ~ carat+x+y)
summary(model1)
summary(model1)
126.00 +25.76*1.65
qnorm(.9)
qnorm(.1)
qnorm(.9)
126.00 +25.76*qnorm(.9)
qnorm(.5)
126.00 +25.76*1.96
summary(model1)
126.00 +25.76*1.96
126.00 +25.76*1.65
